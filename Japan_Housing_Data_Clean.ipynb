{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Dataimport\n",
    "data_link=\"https://raw.githubusercontent.com/Nicki-Bladal/Estimating_Japan_Real_Estate_Pricing_Machine_Learning/master/01.csv\"\n",
    "data_df = pd.read_csv(data_link,parse_dates=True,index_col=\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Listed Categorical variables and Cardinity\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('Prefecture', 1),\n ('Renovation', 2),\n ('Region', 4),\n ('Type', 5),\n ('Purpose', 6),\n ('LandShape', 9),\n ('Direction', 9),\n ('Classification', 14),\n ('CityPlanning', 16),\n ('Remarks', 17),\n ('Structure', 22),\n ('FloorPlan', 26),\n ('TimeToNearestStation', 34),\n ('Period', 57),\n ('Use', 115),\n ('Municipality', 188),\n ('NearestStation', 461),\n ('DistrictName', 4641)]"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Investigating \"Cardinality\" \n",
    "categorical_features = [cname for cname in data_df.columns if data_df[cname].dtype == \"object\"]\n",
    "\n",
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: data_df[col].nunique(), categorical_features))\n",
    "d = dict(zip(categorical_features, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "print(\"Listed Categorical variables and Cardinity\")\n",
    "sorted(d.items(), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing Features for model\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TimeToNearestStation and MaxTimeToNearestStation are removed not to have 3 time factors \n",
    "#Municipality is dropped as Municipality code will suffice\n",
    "#Period is removed as Year + Quarter contain same info\n",
    "# TotalFloorAreaIsGreaterFlag and FrontageIsGreaterFlag are always True and is therefore removed\n",
    "#PricePerTsubo is directly related to Price and is therefore a DataLeakage source which must be removed\n",
    "\n",
    "X=data_df.drop(['Region','MaxTimeToNearestStation','TimeToNearestStation','Municipality','Period', 'BuildingYear','TotalFloorAreaIsGreaterFlag','FrontageIsGreaterFlag','PricePerTsubo', 'Prefecture', 'Classification', 'TotalFloorArea', 'Quarter', 'Breadth', 'FloorPlan', 'AreaIsGreaterFlag', 'NearestStation', 'LandShape', 'Purpose', 'Frontage', 'UnitPrice', 'CoverageRatio', 'PrewarBuilding', 'CityPlanning', 'Structure', 'FloorAreaRatio', 'Renovation', 'TradePrice', 'Remarks', 'Use', 'DistrictName', 'Direction'], axis=1)\n",
    "\n",
    "y=data_df.TradePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 186238 entries, 1 to 186238\nData columns (total 5 columns):\n #   Column                   Non-Null Count   Dtype  \n---  ------                   --------------   -----  \n 0   Type                     186238 non-null  object \n 1   MunicipalityCode         186238 non-null  int64  \n 2   MinTimeToNearestStation  144490 non-null  float64\n 3   Area                     186238 non-null  int64  \n 4   Year                     186238 non-null  int64  \ndtypes: float64(1), int64(3), object(1)\nmemory usage: 8.5+ MB\n"
    }
   ],
   "source": [
    "categorical_features = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "# As the cardinality spans from 2 to more than 4500 we cannot use HotPot imputation for all strings - therefor we stick to object cols\n",
    "\n",
    "# Numericalcolumns\n",
    "numeric_features = [cname for cname in X.columns if data_df[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up trainingdata (for internal test)\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adressing missing values\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('label', OneHotEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the classifiers\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators=10))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('num',\n                                                  Pipeline(memory=None,\n                                                           steps=[('imputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing_values=nan,\n                                                                                 strategy='median',\n                                                                                 verbose=0)),\n                                                                  ('scaler',\n                                                                   StandardScaler(copy=True,\n                                                                                  with_mean...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=10, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "rf.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the accuracy\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean TradePrice 16827899.950869318\nMAE: 11502729.9154317\nRelative Error 0.31644887662661214\n"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_test, preds)\n",
    "\n",
    "print('Mean TradePrice', y.mean())\n",
    "print('MAE:', score)\n",
    "print('Relative Error', (y.mean()-score)/y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda8323ff0e61ae4a6b8857dd46a341f977",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}