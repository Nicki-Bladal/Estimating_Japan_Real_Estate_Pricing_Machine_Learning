{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Dataimport\n",
    "data_link=\"https://raw.githubusercontent.com/Nicki-Bladal/Estimating_Japan_Real_Estate_Pricing_Machine_Learning/master/01.csv\"\n",
    "data_df = pd.read_csv(data_link,parse_dates=True,index_col=\"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing obvious troublesome features\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 186238 entries, 1 to 186238\nData columns (total 37 columns):\n #   Column                       Non-Null Count   Dtype  \n---  ------                       --------------   -----  \n 0   Type                         186238 non-null  object \n 1   Region                       133069 non-null  object \n 2   MunicipalityCode             186238 non-null  int64  \n 3   Prefecture                   186238 non-null  object \n 4   Municipality                 186238 non-null  object \n 5   DistrictName                 183567 non-null  object \n 6   NearestStation               145929 non-null  object \n 7   TimeToNearestStation         144490 non-null  object \n 8   MinTimeToNearestStation      144490 non-null  float64\n 9   MaxTimeToNearestStation      140917 non-null  float64\n 10  TradePrice                   186238 non-null  int64  \n 11  FloorPlan                    20486 non-null   object \n 12  Area                         186238 non-null  int64  \n 13  AreaIsGreaterFlag            186238 non-null  int64  \n 14  UnitPrice                    66260 non-null   float64\n 15  PricePerTsubo                66260 non-null   float64\n 16  LandShape                    132674 non-null  object \n 17  Frontage                     125257 non-null  float64\n 18  FrontageIsGreaterFlag        186238 non-null  bool   \n 19  TotalFloorArea               62490 non-null   float64\n 20  TotalFloorAreaIsGreaterFlag  186238 non-null  int64  \n 21  BuildingYear                 81078 non-null   float64\n 22  PrewarBuilding               186238 non-null  int64  \n 23  Structure                    81430 non-null   object \n 24  Use                          81249 non-null   object \n 25  Purpose                      56882 non-null   object \n 26  Direction                    132631 non-null  object \n 27  Classification               129636 non-null  object \n 28  Breadth                      128012 non-null  float64\n 29  CityPlanning                 152003 non-null  object \n 30  CoverageRatio                140562 non-null  float64\n 31  FloorAreaRatio               140562 non-null  float64\n 32  Period                       186238 non-null  object \n 33  Year                         186238 non-null  int64  \n 34  Quarter                      186238 non-null  int64  \n 35  Renovation                   19731 non-null   object \n 36  Remarks                      6550 non-null    object \ndtypes: bool(1), float64(10), int64(8), object(18)\nmemory usage: 52.8+ MB\nNone\n"
    }
   ],
   "source": [
    "#Checking datatypes and non-null counts\n",
    "print(data_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TimeToNearestStation and MaxTimeToNearestStation are removed not to have 3 time factors\n",
    "del data_df['MaxTimeToNearestStation']\n",
    "del data_df['TimeToNearestStation']    \n",
    "\n",
    "#Municipality is dropped as Municipality code will suffice\n",
    "del data_df['Municipality']\n",
    "\n",
    "#Period is removed as Year + Quarter contain same info\n",
    "del data_df['Period']\n",
    "\n",
    "#All data comes from same prefecture which is therefore kept out\n",
    "del data_df['Prefecture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalFloorAreaIsGreaterFlag and FrontageIsGreaterFlag are always True and is therefore removed\n",
    "data_df.TotalFloorAreaIsGreaterFlag.notnull().mean()\n",
    "\n",
    "del data_df['TotalFloorAreaIsGreaterFlag']\n",
    "del data_df['FrontageIsGreaterFlag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remarks has very few values we inspect it\n",
    "data_df.Remarks.value_counts()\n",
    "\n",
    "# Turns out that a missing remark actually is corrosponding to a remark \n",
    "import numpy as np\n",
    "data_df.Remarks = data_df.Remarks.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataleakage\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PricePerTsubo is directly related to Price and is therefore a DataLeakage source which must be removed\n",
    "del data_df['PricePerTsubo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AreaIsGreaterFlag is a bool, the avg val is 0.12009364361730689 ie. 87.99063563826931 % values are False\nArea is an int, the fraction of observations not equal to zero is 1.0\n"
    }
   ],
   "source": [
    "# Testing Area vs AreaIsGreaterFlag \n",
    "print(\"AreaIsGreaterFlag is a bool, the avg val is\",data_df.AreaIsGreaterFlag.mean(), \"ie.\", (1-data_df.AreaIsGreaterFlag.mean())*100, \"% values are False\")\n",
    "print(\"Area is an int, the fraction of observations not equal to zero is\",data_df.Area.notnull().mean())\n",
    "\n",
    "#AreaIsGreaterFlag is kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting strings and numbers\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Listed Categorical variables and Cardinity\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('Renovation', 2),\n ('Region', 4),\n ('Type', 5),\n ('Purpose', 6),\n ('LandShape', 9),\n ('Direction', 9),\n ('Classification', 14),\n ('CityPlanning', 16),\n ('Remarks', 18),\n ('Structure', 22),\n ('FloorPlan', 26),\n ('Use', 115),\n ('NearestStation', 461),\n ('DistrictName', 4641)]"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "# Investigating \"Cardinality\" \n",
    "object_cols = [cname for cname in data_df.columns if data_df[cname].dtype == \"object\"]\n",
    "\n",
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: data_df[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "print(\"Listed Categorical variables and Cardinity\")\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 186238 entries, 1 to 186238\nData columns (total 29 columns):\n #   Column                   Non-Null Count   Dtype  \n---  ------                   --------------   -----  \n 0   Type                     186238 non-null  object \n 1   Region                   133069 non-null  object \n 2   LandShape                132674 non-null  object \n 3   Purpose                  56882 non-null   object \n 4   Direction                132631 non-null  object \n 5   Renovation               19731 non-null   object \n 6   DistrictName             183567 non-null  object \n 7   NearestStation           145929 non-null  object \n 8   FloorPlan                20486 non-null   object \n 9   Structure                81430 non-null   object \n 10  Use                      81249 non-null   object \n 11  Classification           129636 non-null  object \n 12  CityPlanning             152003 non-null  object \n 13  Remarks                  186238 non-null  object \n 14  MunicipalityCode         186238 non-null  int64  \n 15  MinTimeToNearestStation  144490 non-null  float64\n 16  TradePrice               186238 non-null  int64  \n 17  Area                     186238 non-null  int64  \n 18  AreaIsGreaterFlag        186238 non-null  int64  \n 19  UnitPrice                66260 non-null   float64\n 20  Frontage                 125257 non-null  float64\n 21  TotalFloorArea           62490 non-null   float64\n 22  BuildingYear             81078 non-null   float64\n 23  PrewarBuilding           186238 non-null  int64  \n 24  Breadth                  128012 non-null  float64\n 25  CoverageRatio            140562 non-null  float64\n 26  FloorAreaRatio           140562 non-null  float64\n 27  Year                     186238 non-null  int64  \n 28  Quarter                  186238 non-null  int64  \ndtypes: float64(8), int64(7), object(14)\nmemory usage: 42.6+ MB\nNone\n"
    }
   ],
   "source": [
    "# As the cardinality spans from 2 to more than 4500 we cannot use HotPot imputation for all strings - therefor we divide at cardinality > 10\n",
    "low_cardinality_cols = [cname for cname in data_df.columns if data_df[cname].nunique() < 10 and data_df[cname].dtype == \"object\"]\n",
    "\n",
    "high_cardinality_cols = [cname for cname in data_df.columns if data_df[cname].nunique() > 10 and data_df[cname].dtype == \"object\"]\n",
    "\n",
    "# Numericalcolumns\n",
    "numerical_cols = [cname for cname in data_df.columns if data_df[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + high_cardinality_cols + numerical_cols\n",
    "data_v1 = data_df[my_cols].copy()\n",
    "\n",
    "\n",
    "print(data_v1.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Area is 2.26197300662067 times bigger than TotalFloorArea, with a standard diviation of 2.40680752854744\n"
    }
   ],
   "source": [
    "#Investigating Total floor Area and Area\n",
    "print(\"Area is\", (data_df.Area / data_df.TotalFloorArea).mean(), \"times bigger than TotalFloorArea, with a standard diviation of\", (data_df.Area / data_df.TotalFloorArea).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "719.3651863668237"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "(data_df.TradePrice / data_df.UnitPrice).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda8323ff0e61ae4a6b8857dd46a341f977",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}